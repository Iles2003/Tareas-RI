{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14608380,"sourceType":"datasetVersion","datasetId":612177}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-28T16:39:39.123275Z","iopub.execute_input":"2026-01-28T16:39:39.123667Z","iopub.status.idle":"2026-01-28T16:39:40.984997Z","shell.execute_reply.started":"2026-01-28T16:39:39.123624Z","shell.execute_reply":"2026-01-28T16:39:40.983717Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/arxiv/arxiv-metadata-oai-snapshot.json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Seccion 1 Preprocesamiento de Datos","metadata":{}},{"cell_type":"code","source":"!pip install faiss-cpu sentence-transformers nltk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T16:43:19.257620Z","iopub.execute_input":"2026-01-28T16:43:19.257913Z","iopub.status.idle":"2026-01-28T16:43:56.942233Z","shell.execute_reply.started":"2026-01-28T16:43:19.257889Z","shell.execute_reply":"2026-01-28T16:43:56.941522Z"},"jupyter":{"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"Collecting faiss-cpu\n  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\nRequirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.2)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (26.0rc2)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\nRequirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.1rc0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2026.1.4)\nDownloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.13.2\n","output_type":"stream"},{"name":"stderr","text":"2026-01-28 16:43:39.641413: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769618619.845752      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769618619.901665      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769618620.382667      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769618620.382703      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769618620.382706      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769618620.382708      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"✅ Entorno configurado correctamente (usando FAISS CPU).\n","output_type":"stream"},{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import json\nimport nltk\nimport string\nimport numpy as np\nimport pandas as pd\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\n\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('punkt_tab')\n\nstop_words = set(stopwords.words('english'))\nps = PorterStemmer()\n\ndef preprocess_text(text):\n\n    if not text: return \"\"\n    text = text.lower()\n    tokens = nltk.word_tokenize(text)\n    clean_tokens = [\n        ps.stem(token) for token in tokens \n        if token not in stop_words and token not in string.punctuation\n    ]\n    return \" \".join(clean_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T16:57:45.108558Z","iopub.execute_input":"2026-01-28T16:57:45.109340Z","iopub.status.idle":"2026-01-28T16:57:45.115496Z","shell.execute_reply.started":"2026-01-28T16:57:45.109303Z","shell.execute_reply":"2026-01-28T16:57:45.114780Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# Seccion 2 Representación mediante Embeddings","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\nDATA_PATH = \"/kaggle/input/arxiv/arxiv-metadata-oai-snapshot.json\"\nLIMIT = 10000\n\ndoc_ids = []\nprocessed_docs = [] \nmetadata_map = {}\n\nwith open(DATA_PATH, 'r') as f:\n    for i, line in enumerate(f):\n        if i >= LIMIT: break\n        paper = json.loads(line)\n        \n        full_text = f\"{paper['title']}. {paper['abstract']}\"\n        \n        clean_text = preprocess_text(full_text)\n        \n        doc_ids.append(paper['id'])\n        processed_docs.append(clean_text)\n        \n        metadata_map[paper['id']] = {\n            'title': paper['title'], \n            'abstract': paper['abstract'],\n            'categories': paper['categories']\n        }\n\nmodel_bi = SentenceTransformer('all-MiniLM-L6-v2')\ndoc_embeddings = model_bi.encode(processed_docs, convert_to_numpy=True, show_progress_bar=True)\n\nprint(f\"proceso correcto\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T17:01:54.934133Z","iopub.execute_input":"2026-01-28T17:01:54.934719Z","iopub.status.idle":"2026-01-28T17:02:26.770034Z","shell.execute_reply.started":"2026-01-28T17:01:54.934689Z","shell.execute_reply":"2026-01-28T17:02:26.769238Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/313 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ca7a918180c4adbae4b90ef4353dfb5"}},"metadata":{}},{"name":"stdout","text":"proceso correcto\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"# Seccion 3 Recuperación Inicial (First-Stage Retrieval)","metadata":{}},{"cell_type":"code","source":"import faiss\n\ndimension = doc_embeddings.shape[1]\nindex = faiss.IndexFlatIP(dimension)\nindex.add(doc_embeddings)\n\nprint(f\"Se ha cargado {index.ntotal} vectores.\")\n\ndef search_faiss(query_text, k=20):\n\n    q_clean = preprocess_text(query_text)\n    q_vec = model_bi.encode([q_clean], convert_to_numpy=True)\n    \n    distances, indices = index.search(q_vec, k)\n    \n    results = []\n    for idx, score in zip(indices[0], distances[0]):\n        if idx < 0: continue\n        \n        real_id = doc_ids[idx]\n        meta = metadata_map[real_id]\n        \n        results.append({\n            'doc_id': real_id,\n            'score': float(score),\n            'title': meta['title'],\n            'abstract': meta['abstract'],\n            'categories': meta['categories']\n        })\n    return results\n\nprint(\"proceso correcto\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T17:04:08.452520Z","iopub.execute_input":"2026-01-28T17:04:08.453217Z","iopub.status.idle":"2026-01-28T17:04:08.463868Z","shell.execute_reply.started":"2026-01-28T17:04:08.453186Z","shell.execute_reply":"2026-01-28T17:04:08.463325Z"}},"outputs":[{"name":"stdout","text":"Se ha cargado 10000 vectores.\nproceso correcto\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"# Seccion 4 Re-ranking de Resultados","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import CrossEncoder\n\nmodel_cross = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n\ndef rerank_results(query, initial_hits):\n    if not initial_hits: return []\n    pairs = [[query, f\"{hit['title']} {hit['abstract']}\"] for hit in initial_hits]\n    scores = model_cross.predict(pairs)\n    reranked = []\n    for i, hit in enumerate(initial_hits):\n        hit_copy = hit.copy()\n        hit_copy['rerank_score'] = scores[i]\n        reranked.append(hit_copy)\n    reranked.sort(key=lambda x: x['rerank_score'], reverse=True)\n    \n    return reranked\n\nprint(\"proceso correcto\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T17:05:20.517312Z","iopub.execute_input":"2026-01-28T17:05:20.517943Z","iopub.status.idle":"2026-01-28T17:05:22.647171Z","shell.execute_reply.started":"2026-01-28T17:05:20.517908Z","shell.execute_reply":"2026-01-28T17:05:22.646574Z"}},"outputs":[{"name":"stdout","text":"proceso correcto\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"# Seccion 5 Simulación de Consultas","metadata":{}},{"cell_type":"code","source":"consultas_demo = [\n    \"International conflict\", \n    \"Economic policy news\", \n    \"Natural disasters\"\n]\n\nfor query in consultas_demo:\n    print(f\"\\n se busca: '{query}'\")\n\n    hits_base = search_faiss(query, k=5)\n    \n    hits_rerank = rerank_results(query, hits_base)\n    \n    print(f\"{'ID':<12} | {'Score FAISS':<12} | {'ID':<12} | {'Score Rerank':<12} | {'Título'}\")\n    print(\"-\" * 140)\n    \n    for i in range(len(hits_base)):\n        id_b = hits_base[i]['doc_id']\n        sc_b = f\"{hits_base[i]['score']:.4f}\"\n        id_r = hits_rerank[i]['doc_id']\n        sc_r = f\"{hits_rerank[i]['rerank_score']:.4f}\"\n        title = hits_rerank[i]['title'][:50] + \"...\"\n        \n        print(f\"{id_b:<12} | {sc_b:<12} | {id_r:<12} | {sc_r:<12} | {title}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T17:11:12.865853Z","iopub.execute_input":"2026-01-28T17:11:12.866137Z","iopub.status.idle":"2026-01-28T17:11:12.921317Z","shell.execute_reply.started":"2026-01-28T17:11:12.866114Z","shell.execute_reply":"2026-01-28T17:11:12.920692Z"}},"outputs":[{"name":"stdout","text":"\n se busca: 'International conflict'\nID           | Score FAISS  | ID           | Score Rerank | Título\n--------------------------------------------------------------------------------------------------------------------------------------------\n0705.1209    | 0.3235       | 0705.1209    | -2.0762      | Artificial Intelligence for Conflict Management...\n0706.0100    | 0.2609       | 0705.1761    | -5.8097      | Modeling and Controlling Interstate Conflict...\n0705.1761    | 0.2499       | 0706.0100    | -10.8544     | Evolutionary Dilemmas in a Social Network...\n0705.0403    | 0.2437       | 0705.0233    | -11.2018     | Coordination for a Group of Autonomous Mobile Agen...\n0705.0233    | 0.2437       | 0705.0403    | -11.2313     | Tracking control for multi-agent consensus with an...\n\n se busca: 'Economic policy news'\nID           | Score FAISS  | ID           | Score Rerank | Título\n--------------------------------------------------------------------------------------------------------------------------------------------\n0705.0161    | 0.4456       | 0705.0161    | -8.0774      | Quantitative relations between corruption and econ...\n0704.0664    | 0.3974       | 0704.2139    | -10.6659     | Why only few are so successful ?...\n0705.0891    | 0.3883       | 0704.0664    | -11.1946     | Stock market return distributions: from past to pr...\n0704.2139    | 0.3856       | 0705.2106    | -11.2518     | Scientific citations in Wikipedia...\n0705.2106    | 0.3785       | 0705.0891    | -11.3818     | Opinion Dynamics and Sociophysics...\n\n se busca: 'Natural disasters'\nID           | Score FAISS  | ID           | Score Rerank | Título\n--------------------------------------------------------------------------------------------------------------------------------------------\n0704.2884    | 0.3537       | 0705.1291    | -10.7294     | Spinodal decomposition of low-density asymmetric n...\n0706.1158    | 0.3535       | 0705.2907    | -10.9391     | Peeling and Sliding in Nucleosome Repositioning...\n0705.1291    | 0.3523       | 0704.2884    | -10.9483     | Higher Nilpotent Analogues of A-infinity Structure...\n0705.1012    | 0.3458       | 0706.1158    | -11.1474     | Deformations of Bundles and the Standard Model...\n0705.2907    | 0.3448       | 0705.1012    | -11.1774     | On the Chow ring of the stack of rational nodal cu...\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"# Seccion 6 Evaluación del Sistema","metadata":{}},{"cell_type":"code","source":"test_set = [\n    {\"q\": \"Neural networks image classification\", \"cat\": \"cs\"},       \n    {\"q\": \"Higgs boson particle physics\", \"cat\": \"hep-ph\"},           \n    {\"q\": \"Superconductivity materials\", \"cat\": \"cond-mat\"},          \n    {\"q\": \"Black hole general relativity\", \"cat\": \"gr-qc\"}           \n]\n\ndef calculate_metrics(results, target_cat, k=10):\n    top_k = results[:k]\n    hits = 0\n    for doc in top_k:\n        if target_cat in doc['categories']:\n            hits += 1\n            \n    precision = hits / k\n    recall = hits / min(k, 10) \n    return precision, recall\n\nresults_log = []\n\nfor item in test_set:\n    q = item['q']\n    target = item['cat']\n\n    base = search_faiss(q, k=20)\n    final = rerank_results(q, base)\n\n    p_base, r_base = calculate_metrics(base, target, k=10)\n    p_final, r_final = calculate_metrics(final, target, k=10)\n    \n    results_log.append({\n        'Consulta': q,\n        'P@10 (Base)': p_base,\n        'P@10 (Final)': p_final,\n        'Mejora': p_final - p_base\n    })\n\ndf_metrics = pd.DataFrame(results_log)\nprint(df_metrics)\nprint(\"\\nPromedios:\")\nprint(df_metrics.mean(numeric_only=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T17:08:24.592881Z","iopub.execute_input":"2026-01-28T17:08:24.593531Z","iopub.status.idle":"2026-01-28T17:08:24.800977Z","shell.execute_reply.started":"2026-01-28T17:08:24.593502Z","shell.execute_reply":"2026-01-28T17:08:24.800345Z"}},"outputs":[{"name":"stdout","text":"                               Consulta  P@10 (Base)  P@10 (Final)  Mejora\n0  Neural networks image classification          0.4           0.5     0.1\n1          Higgs boson particle physics          0.9           0.9     0.0\n2           Superconductivity materials          0.9           0.9     0.0\n3         Black hole general relativity          0.8           0.8     0.0\n\nPromedios:\nP@10 (Base)     0.750\nP@10 (Final)    0.775\nMejora          0.025\ndtype: float64\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"# Seccion 7 Análisis de Resultados","metadata":{}},{"cell_type":"markdown","source":"## Análisis\n* El modelo vectorialcon FAISS logro recuperar los documentos que tienen relacion entre si rapidamente.\nComo se puede ver en la tabla evaluación, la metrica de la Precision@10.\n\n* Con la implementacion de re-ranking hubo un cambio significativo en la precisión.\n* Un dato a tener en cuenta es que el model cross encoder en la mayoria de veces sube documentos que tienen en su contenido la respuesta exacta o tiene un contexto específico. Por ello deja de lado aquellos que solo comparten palabras clave pero tienen una diferente contexto. Por ende por mas que mejore la calidad, incrementa el tiempo por consulta.\n\n# Comparacion \n\n* Hay una mejora en la consulta \"Neural networks image classification\", donde la precisión subió de 0.4 a 0.5 (+10%).\n* Se nota que el faiss recuperó documentos generales, pero el cross encoder, al analizar el contexto completo. \n* En la consulta Black hole, Higgs boson, la precisión se mantuvo estable (0.8 - 0.9) sin cambios tras el re-ranking, lo que significa que lo que se recupero ya era optimo. ","metadata":{}},{"cell_type":"markdown","source":"# Stiven Saldaña","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}